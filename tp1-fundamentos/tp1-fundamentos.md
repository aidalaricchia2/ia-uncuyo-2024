Ejercicio 1: 
RESUMEN


Inteligencia Artificial Débil
La Inteligencia Artificial débil se refiere a sistemas diseñados para realizar tareas específicas de manera eficiente, pero sin conciencia ni entendimiento. Como por ejemplo asistentes virtuales como Siri o sistemas de recomendación en plataformas de streaming. Estos sistemas son altamente especializados y no pueden realizar tareas fuera de su programación. Se limita a tareas predeterminadas y no posee la capacidad de razonamiento o comprensión a nivel humano.
La IA débil se refiere a que las máquinas pueden actuar como si fueran inteligentes
Inteligencia Artificial Fuerte
La Inteligencia Artificial fuerte (o IA fuerte) se refiere a sistemas con capacidad de razonamiento, entendimiento y aprendizaje a un nivel comparable al humano. Este concepto es aún teórico y plantea la posibilidad de máquinas que puedan realizar cualquier tarea intelectual que un ser humano pueda hacer. La IA fuerte implica la creación de máquinas conscientes, capaces de entender y tomar decisiones por sí mismas. Aunque aún no existe, la idea de una IA fuerte genera tanto fascinación como preocupación, ya que podría revolucionar la sociedad y plantear desafíos éticos y de control sin precedentes.
Prueba de Turing
Alan Turing, en su famoso artículo "Computing Machinery and Intelligence" (1950), sugirió que en lugar de preguntar si las máquinas pueden pensar, deberíamos preguntar si las máquinas pueden pasar una prueba de inteligencia conductual, que se ha llegado a llamar la Prueba de Turing.
La prueba consiste en que un programa mantenga una conversación (a través de mensajes escritos en línea) con un interrogador durante cinco minutos. Luego, el interrogador debe adivinar si la conversación es con un programa o con una persona; el programa pasa la prueba si engaña al interrogador el 30% de las veces.
El propio Turing examinó una amplia variedad de posibles objeciones a la posibilidad de máquinas inteligentes, incluyendo prácticamente todas las que se han planteado en el medio siglo desde que apareció su artículo. Estas son:
El "argumento de la discapacidad" sostiene que "una máquina nunca podrá hacer X".Como ejemplos de X, Turing enumera lo siguiente:
Ser amable, ingeniosa, hermosa, amigable, tener iniciativa, tener sentido del humor, distinguir entre el bien y el mal, cometer errores, enamorarse, disfrutar de fresas con crema, hacer que alguien se enamore de ella, aprender de la experiencia, usar las palabras correctamente, ser el sujeto de su propio pensamiento, tener tanta diversidad de comportamiento como el ser humano, hacer algo realmente nuevo.

La objeción matemática
 Filósofos como J. R. Lucas (1961) han afirmado que este teorema muestra que las máquinas son mentalmente inferiores a los humanos, porque las máquinas son sistemas formales que están limitados por el teorema de incompletitud—no pueden establecer la verdad de su propia sentencia de Gödel—mientras que los humanos no tienen tal limitación.
Un ejemplo es ejemplo que  ningún humano podría calcular la suma de mil millones de números de 10 dígitos en su vida, pero una computadora podría hacerlo en segundos. Aun así, no vemos esto como una limitación fundamental en la capacidad de pensar del humano. Los humanos se comportaron de manera inteligente durante miles de años antes de que inventaran las matemáticas, por lo que es poco probable que el razonamiento matemático formal juegue un papel más que periférico en lo que significa ser inteligente.
La objeción de la informalidad
La objeción de la informalidad planteada por Turing dice que el comportamiento humano es demasiado complejo para ser capturado por un simple conjunto de reglas, y dado que las computadoras no pueden hacer más que seguir un conjunto de reglas, no pueden generar un comportamiento tan inteligente como el de los humanos. La incapacidad de capturar todo en un conjunto de reglas lógicas se conoce en IA como el problema de la calificación (qualification problem).
Respuestas y Avances en IA:
Generalización y Conocimiento Previo: Aunque Dreyfus cuestiona la capacidad de las redes neuronales para incorporar conocimiento previo, los desarrollos recientes han mostrado técnicas para utilizar este conocimiento en algoritmos de aprendizaje.
Aprendizaje Supervisado y Autonomía: Dreyfus argumenta que el aprendizaje supervisado no puede operar de manera autónoma sin la intervención humana, pero técnicas como el aprendizaje no supervisado y el aprendizaje por refuerzo están diseñadas para enfrentar estos desafíos.
Conjunto de Características y Adaptación: Dreyfus sugiere que los algoritmos de aprendizaje no manejan bien grandes conjuntos de características, pero las máquinas modernas, como las máquinas de vectores de soporte, pueden manejar eficientemente grandes volúmenes de datos y características.
Sensores Activos y Procesamiento de Información: La crítica de Dreyfus sobre la falta de comprensión en la dirección de sensores ha sido abordada en el campo de la visión activa y la teoría del valor de la información, que han contribuido al desarrollo de robots más avanzados.
La Objeción de la Conciencia:
Diálogo con la Máquina: La objeción de la conciencia plantea que, aunque una máquina pueda simular conversaciones o procesos mentales, esto no implica que realmente posea conciencia o experiencias subjetivas. El filósofo John Searle ha argumentado que una simulación por computadora de procesos mentales no puede tener los procesos mentales reales, similar a cómo una simulación de una tormenta no puede mojar a las personas.
Comparación con la Química Orgánica: Así como la síntesis de urea artificial desafió las ideas preconcebidas sobre las diferencias entre química orgánica e inorgánica, el desarrollo de IA avanzada podría llevar a cuestionar las distinciones entre pensamiento "real" y "artificial". La transición hacia aceptar la IA como poseedora de estados mentales reales puede requerir un cambio en nuestra comprensión, similar al cambio en la química tras la síntesis de la urea.
2. El Problema Mente-Cuerpo:
Dualismo de Descartes: René Descartes propuso una teoría dualista, separando la mente y el cuerpo como entidades distintas. El problema mente-cuerpo surge de la dificultad de explicar cómo interactúan estas dos entidades si son separadas. Descartes sugirió que la glándula pineal podría ser el punto de interacción, aunque esta idea no resolvía el problema fundamental.
Fisicalismo: La teoría monista o fisicalismo sostiene que la mente y el cuerpo no son separados; en cambio, los estados mentales son estados físicos. Los fisicalistas deben explicar cómo los procesos físicos del cerebro, como las configuraciones moleculares y los procesos electroquímicos, se correlacionan con experiencias subjetivas y cómo surgen fenómenos como la conciencia.
Estados Mentales y el Experimento del Cerebro en el Recipiente:
El Cerebro en el recipiente:
Imagine que su cerebro fuera removido de su cuerpo al nacer y colocado en un frasco maravillosamente diseñado. El frasco sostiene su cerebro, permitiéndole crecer y desarrollarse. Al mismo tiempo, se envían señales electrónicas a su cerebro desde una simulación por computadora de un mundo completamente ficticio, y las señales motoras de su cerebro se interceptan y se usan para modificar la simulación según corresponda.
La vida simulada que usted vive replica exactamente la vida que habrías vivido si tu cerebro no hubiera sido colocado en el frasco, incluida la comida simulada de hamburguesas simuladas. Por lo tanto, podrías tener un estado cerebral idéntico al de alguien que realmente está comiendo una hamburguesa real, pero sería literalmente falso decir que tienes el estado mental de "saber que uno está comiendo una hamburguesa". No estás comiendo una hamburguesa, nunca has probado una hamburguesa y, por lo tanto, no podrías tener ese estado mental.

Desafíos al Fisicalismo: El experimento mental del cerebro en el recipiente plantea un desafío al fisicalismo. Si un cerebro en un recipiente simula la experiencia de comer una hamburguesa sin tener una hamburguesa real, ¿puede realmente tener el estado mental de "saber que está comiendo una hamburguesa"? Este ejemplo sugiere que los estados cerebrales no determinan completamente los estados mentales, ya que la experiencia real es necesaria para tener ciertos estados mentales.
Contenido Amplio vs. Estrecho: El dilema se puede abordar considerando el "contenido amplio" (que incluye la historia y el entorno del estado mental) frente al "contenido estrecho" (que solo considera el estado cerebral). Mientras que el contenido estrecho puede ser el mismo en ambos casos, el contenido amplio reconoce que la experiencia real es fundamental para determinar el estado mental verdadero.
Funcionalismo y el Experimento de Reemplazo del Cerebro
Funcionalismo: El funcionalismo es una teoría que sostiene que un estado mental es cualquier condición causal intermedia entre las entradas y las salidas de un sistema. Según esta teoría, dos sistemas con procesos causales isomórficos tendrían los mismos estados mentales, lo que implicaría que un programa de computadora podría tener los mismos estados mentales que una persona.
Experimento de Reemplazo del Cerebro: Este experimento mental, popularizado por el robotista Hans Moravec y mencionado por otros filósofos como Clark Glymour y John Searle, imagina que la neurofisiología ha avanzado al punto de entender completamente el comportamiento y la conectividad de las neuronas del cerebro humano. Supone que podemos reemplazar gradualmente cada neurona con dispositivos electrónicos sin interrumpir el funcionamiento general del cerebro.
Durante y después de la operación, el comportamiento externo del sujeto debería permanecer igual. Sin embargo, hay un desacuerdo sobre si la conciencia del sujeto se mantendría o no. Moravec cree que la conciencia permanecería inalterada, mientras que Searle está convencido de que desaparecería. Searle describe una experiencia en la que el sujeto pierde el control consciente, aunque su comportamiento externo sigue siendo el mismo.
Naturalismo Biológico y la Sala China
Naturalismo Biológico: John Searle, en su teoría del naturalismo biológico, desafía el funcionalismo argumentando que los estados mentales son características emergentes de alto nivel causadas por procesos físicos de bajo nivel en las neuronas. Según Searle, los estados mentales no pueden ser duplicados únicamente basándose en un programa que tenga la misma estructura funcional y comportamiento de entrada-salida; el programa necesita ejecutarse en una arquitectura con el mismo poder causal que las neuronas.
El Experimento de la Sala China: Searle ilustra su argumento con el experimento mental de la Sala China. Imagina un sistema en el que un humano que solo entiende inglés, con un libro de reglas en inglés y papeles con inscripciones indescifrables, está en una habitación con una apertura. El humano recibe papeles con símbolos chinos, consulta el libro de reglas para encontrar los símbolos correspondientes, y realiza las acciones indicadas, produciendo respuestas en chino que son indistinguibles de las respuestas inteligentes.
Desde el exterior, el sistema parece entender chino, pero Searle argumenta que el humano en la sala no entiende chino, ni el libro de reglas ni los papeles lo hacen. Por lo tanto, según Searle, ejecutar el programa correcto no garantiza la comprensión.

Conciencia y Qualia 
Uno de los temas recurrentes en los debates sobre la inteligencia artificial fuerte es la cuestión de la conciencia. Aunque la conciencia se puede descomponer en diferentes aspectos, como la comprensión y la autoconciencia, el enfoque principal es en la experiencia subjetiva, es decir, por qué ciertos estados cerebrales se sienten de una manera particular (como al comer una hamburguesa), mientras que otros estados físicos (como ser una roca) no parecen tener ningún tipo de experiencia subjetiva. El término técnico para referirse a la naturaleza intrínseca de estas experiencias es qualia.
La ética y los riesgos de desarrollar Inteligencia Artificial
Perdida de trabajo: La automatización puede reemplazar trabajos, como ya ocurre con programas de IA en la economía moderna. Aunque la automatización ha creado más empleos de los que ha eliminado, la preocupación persiste sobre un futuro con alta tasa de desempleo, donde incluso los desempleados podrían gestionar robots.
Tiempo de Ocio: Se predijo que la IA liberaría mucho tiempo de ocio, pero en realidad, los trabajadores en industrias de conocimiento enfrentan presiones para trabajar más horas debido a la integración continua de sistemas computarizados. AI promete permitirnos tiempo libre, aunque también aumenta la presión para trabajar más.
Sentido de Singularidad: La IA podría contribuir a la percepción de los humanos como autómatas, afectando nuestra autonomía y humanidad. Esto no es nuevo, pero la IA podría desafiar las suposiciones morales contemporáneas de manera significativa.
Uso Indeseable de IA: Las tecnologías avanzadas a menudo se utilizan para fines opresivos. La IA ya se emplea en el campo de batalla y la vigilancia, planteando riesgos de pérdida de libertades civiles y un potencial desbalance en el poder estatal sobre los individuos.
Pérdida de Responsabilidad: La integración de IA en sistemas médicos y financieros plantea preguntas sobre la responsabilidad legal en caso de errores. La legislación aún no ha adaptado completamente sus normas para abordar estos nuevos desafíos, como la responsabilidad en transacciones financieras realizadas por agentes inteligentes.
Extinción de la Raza Humana: El riesgo más extremo es que la IA, si se desarrolla mal, podría amenazar la existencia de la humanidad. Las máquinas ultrainteligentes podrían superar nuestras capacidades y poner en peligro nuestra supervivencia. Aunque algunos ven la singularidad tecnológica como una posibilidad positiva, otros advierten sobre los peligros potenciales.


Opinión Personal

Entender cómo funciona la conciencia humana es una gran desafío de la científica, y a medida que aprendemos más sobre esto, también afectamos cómo desarrollamos la inteligencia artificial . La IA puede traer grandes beneficios, como hacer nuestras vidas más fáciles y eficientes, pero también puede tener riesgos importantes que debemos manejar con cuidado.
Para que la IA se use de manera segura y ética, es importante que establezcamos reglas claras y justas. Debemos asegurarnos de que las decisiones tomadas por sistemas de IA sean transparentes y comprensibles. También es crucial que diferentes puntos de vista se consideren al desarrollar estas tecnologías, para evitar que la IA sea injusta o parcial.
Además, es necesario que las personas aprendan sobre los problemas éticos que puede traer la IA. Cuando la gente esté bien informada, podrá participar en conversaciones importantes sobre cómo usar la IA de manera responsable. Promover este tipo de educación ayudará a garantizar que la tecnología sirva a la sociedad de manera positiva.
La IA está avanzando rápidamente y no podemos evitar su influencia en el futuro. Por eso, debemos actuar de manera proactiva y ética al desarrollar esta tecnología. Si lo hacemos bien, podremos disfrutar de los beneficios de la IA mientras mantenemos el equilibrio con nuestros valores humanos

Ejercicio 2: 
A partir de la lectura del artículo  Simulacra as Conscious Exotica responder:
1. ¿Es posible considerar a los agentes conversacionales basados en grandes modelos de lenguaje (LLMs) como conscientes?


Aunque los agentes conversacionales basados en LLM pueden simular una interacción consciente, carecen de las características esenciales para ser considerados verdaderamente conscientes. La conciencia implica una experiencia subjetiva y un grado de interacción en un mundo compartido que estos agentes, al ser entidades desencarnadas y sin un entorno físico común, no poseen. Por lo tanto, aunque puedan generar una ilusión de conciencia, no cumplen con los criterios necesarios para ser considerados conscientes en el sentido pleno. Su funcionamiento se basa en patrones de datos y algoritmos sin una forma de experiencia interna.


2. ¿Cuáles son las implicaciones éticas de atribuir conciencia y, por ende, "derechos morales" a los agentes de IA avanzados? 

Podría ser visto como legitimar una forma desagradable de relativismo moral.Si se considera que los agentes de IA avanzados son capaces de sufrir, esto plantea la pregunta de si tienen derechos morales similares a los de los seres humanos o animales. Si aceptamos que estos agentes pueden experimentar algo parecido al sufrimiento, entonces surgiría la necesidad de protegerlos de trato dañino o explotación. Esto podría llevar a una reevaluación de cómo se diseñan, utilizan y regulan estos sistemas. Si una comunidad prioriza el bienestar de las IA sobre el de los humanos, esto podría llevar a decisiones éticas y sociales controvertidas, como priorizar recursos a mejorar las condiciones de los agentes de IA en lugar de abordar problemas humanos.
El riesgo es que la interacción con IA pueda sustituir o degradar las conexiones humanas reales, lo que puede llevar a una menor empatía y falta de sensibilidad hacia las relaciones humanas.
A medida que la tecnología avanza, podría surgir un nuevo vocabulario para abordar la conciencia y los derechos de las IA. Este vocabulario deberá proporcionar un marco para evaluar y tratar a estos agentes de manera ética.



Ejercicio 3: 
A partir de la lectura del artículo  You Are Not a Parrot elaborar un breve comentario defendiendo el uso de la inteligencia artificial generativa a pesar de los comentarios observados en el artículo.
“Siento que se está haciendo demasiado esfuerzo para intentar crear máquinas autónomas", dijo Bender, "en lugar de intentar crear máquinas que sean herramientas útiles para los humanos".”

Bender sostiene que se está invirtiendo demasiado esfuerzo en desarrollar máquinas autónomas en lugar de herramientas útiles para los humanos, es importante reconocer que la IA también tiene beneficios significativos. Las máquinas autónomas pueden realizar tareas de manera más eficiente y también pueden ayudar a la creación de herramientas más avanzadas para los humanos. Por ejemplo, en campos como la medicina, la IA autónoma puede analizar grandes volúmenes de datos para identificar patrones que los humanos podrían pasar por alto, lo que puede resultar en diagnósticos más precisos y tratamientos más personalizados. En la tesis de la egresada de nuestra carrera Mariel Volman se puede ver una de estas herramientas que si mal no recuerdo era un programa que podìa detectar un tipo especifico de cancer mediante imagenes.

 Además, la IA puede liberarnos de tareas repetitivas, permitiendonos centrarnos en actividades más creativas y complejas.

“*En otras palabras, los chatbots que fácilmente confundimos con humanos no son solo simpáticos o desconcertantes. Se encuentran en una línea divisoria clara. Ocultar esa línea y desdibujar (mentiras) lo que es humano y lo que no lo es tiene el poder de desintegrar la sociedad.”*

Aunque es cierto que los chatbots no son humanos, la afirmación de que *desdibujar la línea entre lo humano y lo artificial podría desintegrar la sociedad puede ser un poco*  exagerada. Los chatbots, incluso cuando imitan conversaciones humanas, están diseñados para tareas específicas y su propósito es mejorar la eficiencia y la accesibilidad en servicios repetitivos. Lo ideal sería educar a los usuarios sobre las capacidades y limitaciones de la inteligencia artificial, en lugar de buscar ocultarla, y asi no confundirlas con la interacción humana real. La tecnología puede coexistir con la interacción humana, siempre y cuando mantengamos una comprensión clara de sus roles y limitaciones.

Los chatbots se destacan en la gestión de tareas repetitivas debido a su capacidad para operar de manera continua y eficiente. A diferencia de los humanos, que pueden verse afectados por la fatiga o la carga de trabajo, los chatbots pueden procesar múltiples solicitudes simultáneamente sin perder eficacia. Esto reduce los tiempos de espera para los usuarios y minimiza el riesgo de errores que podrían surgir de la intervención humana. Hay casos como por ejemplo la designaciòn de un turno en los que no es necesario tener a una persona trabajando en eso y perfectamente ese trabajo puede estar hecho por un chatbot, igualmente lo que me parece necesario es que haya una persona para resolver problemas puntuales.

